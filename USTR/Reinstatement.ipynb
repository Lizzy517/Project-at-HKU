{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellawu/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 爬取链接网页\n",
    "def get_submission_data(driver, link):\n",
    "    # 打开链接网页并切换到新窗口\n",
    "    driver.execute_script(\"window.open();\")\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    driver.get(link)\n",
    "\n",
    "    # 显示等待，等待页面中的特定元素加载完成\n",
    "    time.sleep(3)\n",
    "\n",
    "    # 使用Beautiful Soup解析页面源代码\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # 定义一个辅助函数来提取字段值，处理可能的缺失字段\n",
    "    def extract_field(field_name):\n",
    "        field = soup.find('span', string=field_name)\n",
    "        if field:\n",
    "            return field.find_next('div', class_='slds-form-element__static').text\n",
    "        return None\n",
    "\n",
    "    # 提取链接对应页面的数据\n",
    "    submission_data = {\n",
    "        #'Submission ID': extract_field('Submission ID'),\n",
    "        'Full Organization Legal Name': extract_field('Full Organization Legal Name'),\n",
    "        'Third Party': extract_field('Third Party'),\n",
    "        'Third Party Organization Name': extract_field('Third Party Organization Name'),\n",
    "        'Exclusion Product Description':extract_field('Exclusion Product Description'),\n",
    "        'Is this product subject to an antidumping (AD) or countervailing duty (CVD) order issued by the U.S. Department of Commerce?': extract_field('Is this product subject to an antidumping (AD) or countervailing duty (CVD) order issued by the U.S. Department of Commerce?'),\n",
    "        'Does your business meet the size standards for a small business as established by the Small Business Administration?': extract_field('Does your business meet the size standards for a small business as established by the Small Business Administration?'),\n",
    "        'Please report the number of employees your business employs in the United States.':extract_field('Please report the number of employees your business employs in the United States.'),\n",
    "        'Do you support reinstating the exclusion?': extract_field('Do you support reinstating the exclusion?'),\n",
    "        'Please explain your rationale.':extract_field('Please explain your rationale.'),\n",
    "        'Are you a domestic producer of the products covered by this exclusion?': extract_field('Are you a domestic producer of the products covered by this exclusion?'),\n",
    "        'Please explain whether the products covered by the exclusion, or comparable products, are available from sources in the United States?': extract_field('Please explain whether the products covered by the exclusion, or comparable products, are available from sources in the United States?'),\n",
    "        'Please explain whether the products covered by the exclusion, or comparable products, are available from sources in third countries?': extract_field('Please explain whether the products covered by the exclusion, or comparable products, are available from sources in third countries?')\n",
    "    }\n",
    "    #print(submission_data)\n",
    "\n",
    "    # 关闭链接网页并切换回原窗口\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    return submission_data\n",
    "\n",
    "# 爬取第一层网页并存储数据\n",
    "def scrape_ustr_comments(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    data = {\n",
    "        'Submission ID': [],\n",
    "        'Organization Name': [],\n",
    "        'Published Exclusion Number': [],\n",
    "        'Exclusion Product Description': [],\n",
    "        'Date Posted': [],\n",
    "        'Link': [],\n",
    "        'Full Organization Legal Name': [],\n",
    "        'Third Party': [],\n",
    "        'Third Party Organization Name': [],\n",
    "        'Is this product subject to an antidumping (AD) or countervailing duty (CVD) order issued by the U.S. Department of Commerce?': [],\n",
    "        'Does your business meet the size standards for a small business as established by the Small Business Administration?': [],\n",
    "        'Please report the number of employees your business employs in the United States.':[],\n",
    "        'Do you support reinstating the exclusion?':[],\n",
    "        'Please explain your rationale.': [],\n",
    "        'Are you a domestic producer of the products covered by this exclusion?':[],\n",
    "        'Please explain whether the products covered by the exclusion, or comparable products, are available from sources in the United States?': [],\n",
    "        'Please explain whether the products covered by the exclusion, or comparable products, are available from sources in third countries?': [],\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        time.sleep(4)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        tbody = soup.find('table').find('tbody') if soup.find('table') else None\n",
    "        if tbody:\n",
    "            for row in tbody.find_all('tr'):\n",
    "                submission_id = row.find('a', href=True).text\n",
    "                organization_name = row.find_all('td')[0].text\n",
    "                published_exclusion_number = row.find_all('td')[1].text\n",
    "                exclusion_product_description = row.find_all('td')[2].text\n",
    "                date_posted = row.find_all('td')[3].text\n",
    "                link = f\"https://comments.ustr.gov{row.find('a', href=True)['href']}\"\n",
    "\n",
    "                submission_data = get_submission_data(driver, link)\n",
    "\n",
    "                data['Submission ID'].append(submission_id)\n",
    "                data['Organization Name'].append(organization_name)\n",
    "                data['Published Exclusion Number'].append(published_exclusion_number)\n",
    "                data['Exclusion Product Description'].append(exclusion_product_description)\n",
    "                data['Date Posted'].append(date_posted)\n",
    "                data['Link'].append(link)\n",
    "                \n",
    "                #print(submission_id)\n",
    "                #print(organization_name)\n",
    "\n",
    "                for field, value in submission_data.items():\n",
    "                    data[field].append(value)\n",
    "        \n",
    "        # 翻页\n",
    "        next_button = driver.find_element(\"xpath\", \"//button[contains(@class, 'slds-button_neutral') and contains(text(), 'Next')]\")\n",
    "        \n",
    "        if \"aria-disabled=\\\"true\\\"\" in next_button.get_attribute(\"outerHTML\"):\n",
    "            break\n",
    "\n",
    "        next_button.click()\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    max_length = max(len(value) for value in data.values())\n",
    "\n",
    "# 填充缺失值，使所有字段具有相同的长度\n",
    "    filled_data = {field: value + [None] * (max_length - len(value)) for field, value in data.items()}\n",
    "\n",
    "# 创建数据框架\n",
    "    df = pd.DataFrame(filled_data)\n",
    "    df.to_excel('ustr_comments_data_2021-0019.xlsx', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://comments.ustr.gov/s/docket?docketNumber=USTR-2021-0019'\n",
    "    scrape_ustr_comments(url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
