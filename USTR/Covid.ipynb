{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabellawu/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 爬取链接网页\n",
    "def get_submission_data(driver, link):\n",
    "    # 打开链接网页并切换到新窗口\n",
    "    driver.execute_script(\"window.open();\")\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    driver.get(link)\n",
    "\n",
    "    # 显示等待，等待页面中的特定元素加载完成\n",
    "    time.sleep(6)\n",
    "\n",
    "    # 使用Beautiful Soup解析页面源代码\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # 定义一个辅助函数来提取字段值，处理可能的缺失字段\n",
    "    def extract_field(field_name):\n",
    "        field = soup.find('span', string=field_name)\n",
    "        if field:\n",
    "            return field.find_next('div', class_='slds-form-element__static').text\n",
    "        return None\n",
    "\n",
    "    # 提取链接对应页面的数据\n",
    "    submission_data = {\n",
    "        #'Submission ID': extract_field('Submission ID'),\n",
    "        'Are you a third party, such as a law firm, trade association, or customs broker, submitting on behalf of an organization or industry? (OPTIONAL)': extract_field('Are you a third party, such as a law firm, trade association, or customs broker, submitting on behalf of an organization or industry? (OPTIONAL)'),\n",
    "        '[2] Please select the COVID-related exclusion set to expire on September 30, 2021 related to your comment:': extract_field('[2] Please select the COVID-related exclusion set to expire on September 30, 2021 related to your comment:'),\n",
    "        '[3] Do you support extending the exclusion beyond September 30, 2021 (yes or no)?': extract_field('[3] Do you support extending the exclusion beyond September 30, 2021 (yes or no)?'),\n",
    "        '[4] Please provide your rationale for supporting or opposing an extension.': extract_field('[4] Please provide your rationale for supporting or opposing an extension.'),\n",
    "        'Third Party Organizational Type (OPTIONAL)': extract_field('Third Party Organizational Type (OPTIONAL)'),\n",
    "        'Third Party Firm, Association Name (OPTIONAL)': extract_field('Third Party Firm, Association Name (OPTIONAL)'),\n",
    "        'Third Party Representative (REQUIRED)': extract_field('Third Party Representative (REQUIRED)')\n",
    "    }\n",
    "    #print(submission_data)\n",
    "\n",
    "    # 关闭链接网页并切换回原窗口\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    return submission_data\n",
    "\n",
    "# 爬取第一层网页并存储数据\n",
    "def scrape_ustr_comments(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    data = {\n",
    "        'Submission ID': [],\n",
    "        'Commenter First Name': [],\n",
    "        'Commenter Last Name': [],\n",
    "        'Organization Name': [],\n",
    "        'Annex List': [],\n",
    "        'Link':[],\n",
    "        'Are you a third party, such as a law firm, trade association, or customs broker, submitting on behalf of an organization or industry? (OPTIONAL)': [],\n",
    "        '[2] Please select the COVID-related exclusion set to expire on September 30, 2021 related to your comment:': [],\n",
    "        '[3] Do you support extending the exclusion beyond September 30, 2021 (yes or no)?': [],\n",
    "        '[4] Please provide your rationale for supporting or opposing an extension.': [],\n",
    "        'Third Party Organizational Type (OPTIONAL)': [],\n",
    "        'Third Party Firm, Association Name (OPTIONAL)': [],\n",
    "        'Third Party Representative (REQUIRED)': [],\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        time.sleep(5)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        tbody = soup.find('table').find('tbody') if soup.find('table') else None\n",
    "        if tbody:\n",
    "            for row in tbody.find_all('tr'):\n",
    "                submission_id = row.find('a', href=True).text\n",
    "                commenter_first_name = row.find_all('td')[0].text\n",
    "                commenter_last_name = row.find_all('td')[1].text\n",
    "                organization_name = row.find_all('td')[2].text\n",
    "                annex_list = row.find_all('td')[3].text\n",
    "                link = f\"https://comments.ustr.gov{row.find('a', href=True)['href']}\"\n",
    "\n",
    "                submission_data = get_submission_data(driver, link)\n",
    "\n",
    "                data['Submission ID'].append(submission_id)\n",
    "                data['Commenter First Name'].append(commenter_first_name)\n",
    "                data['Commenter Last Name'].append(commenter_last_name)\n",
    "                data['Organization Name'].append(organization_name)\n",
    "                data['Annex List'].append(annex_list)\n",
    "                data['Link'].append(link)\n",
    "                \n",
    "                #print(submission_id)\n",
    "                #print(organization_name)\n",
    "\n",
    "                for field, value in submission_data.items():\n",
    "                    data[field].append(value)\n",
    "        \n",
    "        # 翻页\n",
    "        next_button = driver.find_element(\"xpath\", \"//button[contains(@class, 'slds-button_neutral') and contains(text(), 'Next')]\")\n",
    "        \n",
    "        if \"aria-disabled=\\\"true\\\"\" in next_button.get_attribute(\"outerHTML\"):\n",
    "            break\n",
    "\n",
    "        next_button.click()\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel('USTR-2021-0010.xlsx', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://comments.ustr.gov/s/docket?docketNumber=USTR-2021-0010'\n",
    "    scrape_ustr_comments(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 爬取链接网页\n",
    "def get_submission_data(driver, link):\n",
    "    # 打开链接网页并切换到新窗口\n",
    "    driver.execute_script(\"window.open();\")\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    driver.get(link)\n",
    "\n",
    "    # 显示等待，等待页面中的特定元素加载完成\n",
    "    time.sleep(3)\n",
    "\n",
    "    # 使用Beautiful Soup解析页面源代码\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # 定义一个辅助函数来提取字段值，处理可能的缺失字段\n",
    "    def extract_field(field_name):\n",
    "        field = soup.find('span', string=field_name)\n",
    "        if field:\n",
    "            return field.find_next('div', class_='slds-form-element__static').text\n",
    "        return None\n",
    "\n",
    "    # 提取链接对应页面的数据\n",
    "    submission_data = {\n",
    "        #'Submission ID': extract_field('Submission ID'),\n",
    "        'Are you a third party, such as a law firm, trade association, or customs broker, submitting on behalf of an organization or industry? (OPTIONAL)': extract_field('Are you a third party, such as a law firm, trade association, or customs broker, submitting on behalf of an organization or industry? (OPTIONAL)'),\n",
    "        '[1] For the COVID-related exclusion, please select the List(Annex) associated with the covered product.': extract_field('[1] For the COVID-related exclusion, please select the List(Annex) associated with the covered product.'),\n",
    "        '[2] Please select the COVID-related exclusion you wish to comment on.': extract_field('[2] Please select the COVID-related exclusion you wish to comment on.'),\n",
    "        '[3] Do you support extending the exclusion beyond May 15, 2023 (yes or no)?': extract_field('[3] Do you support extending the exclusion beyond May 15, 2023 (yes or no)?'),\n",
    "        '[4] Please provide your rationale for supporting or opposing an extension.': extract_field('[4] Please provide your rationale for supporting or opposing an extension.'),\n",
    "        '[5] Please explain whether the products covered by the exclusion are available from sources in the United States or third countries? (Please include information concerning changes in the global supply chain since 2020 with respect to the particular product or any other relevant industry developments).': extract_field('[5] Please explain whether the products covered by the exclusion are available from sources in the United States or third countries? (Please include information concerning changes in the global supply chain since 2020 with respect to the particular product or any other relevant industry developments).'),\n",
    "        '[6] Please comment on whether extending or not extending the exclusion will impact the domestic supply of products covered by the exclusion, including the price and availability of the product.': extract_field('[6] Please comment on whether extending or not extending the exclusion will impact the domestic supply of products covered by the exclusion, including the price and availability of the product.')\n",
    "    }\n",
    "    #print(submission_data)\n",
    "\n",
    "    # 关闭链接网页并切换回原窗口\n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    return submission_data\n",
    "\n",
    "# 爬取第一层网页并存储数据\n",
    "def scrape_ustr_comments(url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    data = {\n",
    "        'Submission ID': [],\n",
    "        'Commenter First Name': [],\n",
    "        'Commenter Last Name': [],\n",
    "        'Organization Name': [],\n",
    "        'Annex List': [],\n",
    "        'Link':[],\n",
    "        'Are you a third party, such as a law firm, trade association, or customs broker, submitting on behalf of an organization or industry? (OPTIONAL)': [],\n",
    "        '[1] For the COVID-related exclusion, please select the List(Annex) associated with the covered product.': [],\n",
    "        '[2] Please select the COVID-related exclusion you wish to comment on.': [],\n",
    "        '[3] Do you support extending the exclusion beyond May 15, 2023 (yes or no)?': [],\n",
    "        '[4] Please provide your rationale for supporting or opposing an extension.': [],\n",
    "        '[5] Please explain whether the products covered by the exclusion are available from sources in the United States or third countries? (Please include information concerning changes in the global supply chain since 2020 with respect to the particular product or any other relevant industry developments).': [],\n",
    "        '[6] Please comment on whether extending or not extending the exclusion will impact the domestic supply of products covered by the exclusion, including the price and availability of the product.': [],\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        time.sleep(3)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        tbody = soup.find('table').find('tbody') if soup.find('table') else None\n",
    "        if tbody:\n",
    "            for row in tbody.find_all('tr'):\n",
    "                submission_id = row.find('a', href=True).text\n",
    "                commenter_first_name = row.find_all('td')[0].text\n",
    "                commenter_last_name = row.find_all('td')[1].text\n",
    "                organization_name = row.find_all('td')[2].text\n",
    "                annex_list = row.find_all('td')[3].text\n",
    "                link = f\"https://comments.ustr.gov{row.find('a', href=True)['href']}\"\n",
    "\n",
    "                submission_data = get_submission_data(driver, link)\n",
    "\n",
    "                data['Submission ID'].append(submission_id)\n",
    "                data['Commenter First Name'].append(commenter_first_name)\n",
    "                data['Commenter Last Name'].append(commenter_last_name)\n",
    "                data['Organization Name'].append(organization_name)\n",
    "                data['Annex List'].append(annex_list)\n",
    "                data['Link'].append(link)\n",
    "                \n",
    "                #print(submission_id)\n",
    "                #print(organization_name)\n",
    "\n",
    "                for field, value in submission_data.items():\n",
    "                    data[field].append(value)\n",
    "        \n",
    "        # 翻页\n",
    "        next_button = driver.find_element(\"xpath\", \"//button[contains(@class, 'slds-button_neutral') and contains(text(), 'Next')]\")\n",
    "        \n",
    "        if \"aria-disabled=\\\"true\\\"\" in next_button.get_attribute(\"outerHTML\"):\n",
    "            break\n",
    "\n",
    "        next_button.click()\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel('USTR-2023-0001.xlsx', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://comments.ustr.gov/s/docket?docketNumber=USTR-2023-0001'\n",
    "    scrape_ustr_comments(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
